{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8d3c967",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef062b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a function extracting on 1 feature for the model\n",
    "def extract_features(signal):\n",
    "    return [\n",
    "        #mfcc\n",
    "        librosa.feature.mfcc(y=signal,n_mfcc=20)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fcdff7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103 car training signals - 96 tram training signals\n",
      "18 car validation signals - 21 tram validation signals\n",
      "20 car testing signals - 20 tram testing signals\n"
     ]
    }
   ],
   "source": [
    "#REPLACE THE TESTING DATA PATH WITH DESIRED PATH\n",
    "#training data\n",
    "path_car_train = 'training/car/*.wav'\n",
    "path_tram_train = 'training/tram/*.wav'\n",
    "#validation data\n",
    "path_car_valid = 'validation/car/*.wav'\n",
    "path_tram_valid = 'validation/tram/*.wav'\n",
    "#testing data\n",
    "path_car_test = 'testing/car/*.wav'\n",
    "path_tram_test = 'testing/tram/*.wav'\n",
    "\n",
    "car_train = [librosa.load(os.fspath(p))[0] for p in Path().glob(path_car_train)]\n",
    "tram_train = [librosa.load(os.fspath(p))[0] for p in Path().glob(path_tram_train)]\n",
    "print('{} car training signals - {} tram training signals'.format(len(car_train), len(tram_train)))\n",
    "\n",
    "car_valid = [librosa.load(os.fspath(p))[0] for p in Path().glob(path_car_valid)]\n",
    "tram_valid = [librosa.load(os.fspath(p))[0] for p in Path().glob(path_tram_valid)]\n",
    "print('{} car validation signals - {} tram validation signals'.format(len(car_valid), len(tram_valid)))\n",
    "\n",
    "car_test = [librosa.load(os.fspath(p))[0] for p in Path().glob(path_car_test)]\n",
    "tram_test = [librosa.load(os.fspath(p))[0] for p in Path().glob(path_tram_test)]\n",
    "print('{} car testing signals - {} tram testing signals'.format(len(car_test), len(tram_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee7747a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train class array size: (199, 1)\n",
      "Train data array size: (199, 20)\n",
      "Validation vlass array size: (39, 1)\n",
      "Validation data array size: (39, 20)\n",
      "Testing class array size: (40, 1)\n",
      "Testing data array size: (40, 20)\n"
     ]
    }
   ],
   "source": [
    "#Preparing the data and the corresponding ground truth classes\n",
    "'''\n",
    "In this part, for simplicity later in the model, we will prepare the data\n",
    "and its corresponding class (car/tram) (in case ground truth class is not provided)\n",
    "\n",
    "For the corresponding class:\n",
    "    - Car = \"1\"\n",
    "    - Tram = \"0\"\n",
    "'''\n",
    "#training data\n",
    "train_class1 = np.ones((len(car_train),1))\n",
    "train_class2 = np.zeros((len(tram_train),1))\n",
    "train_class = np.concatenate((train_class1, train_class2))\n",
    "car_features_train = np.array([np.mean(extract_features(x),axis=2) for x in car_train])\n",
    "tram_features_train = np.array([np.mean(extract_features(x),axis=2) for x in tram_train])\n",
    "train_data = np.vstack((car_features_train, tram_features_train))\n",
    "train_data[:,0] = train_data[:,0]/train_data[:,0].max() #normalizing\n",
    "train_data = train_data.reshape((int(len(car_train) + len(tram_train)), 20)) #reshaping\n",
    "\n",
    "print(\"Train class array size: \" + str(train_class.shape))\n",
    "print(\"Train data array size: \" + str(train_data.shape))\n",
    "\n",
    "#validation data\n",
    "valid_class1 = np.ones((len(car_valid), 1))\n",
    "valid_class2 = np.zeros((len(tram_valid), 1))\n",
    "valid_class = np.concatenate((valid_class1, valid_class2))\n",
    "car_features_valid = np.array([np.mean(extract_features(x),axis=2) for x in car_valid])\n",
    "tram_features_valid = np.array([np.mean(extract_features(x),axis=2) for x in tram_valid])\n",
    "valid_data = np.vstack((car_features_valid, tram_features_valid))\n",
    "valid_data[:,0] = valid_data[:,0]/valid_data[:,0].max() #normalizing\n",
    "valid_data = valid_data.reshape((int(len(car_valid) + len(tram_valid)), 20)) #reshaping\n",
    "\n",
    "print(\"Validation vlass array size: \" + str(valid_class.shape))\n",
    "print(\"Validation data array size: \" + str(valid_data.shape))\n",
    "\n",
    "#testing data\n",
    "test_class1 = np.ones((len(car_test), 1))\n",
    "test_class2 = np.zeros((len(tram_test), 1))\n",
    "test_class = np.concatenate((test_class1, test_class2))\n",
    "car_features_test = np.array([np.mean(extract_features(x),axis=2) for x in car_test])\n",
    "tram_features_test = np.array([np.mean(extract_features(x),axis=2) for x in tram_test])\n",
    "test_data = np.vstack((car_features_test, tram_features_test))\n",
    "test_data[:,0] =test_data[:,0]/test_data[:,0].max() #normalizing\n",
    "test_data = test_data.reshape((int(len(car_test) + len(tram_test)), 20)) #reshaping\n",
    "\n",
    "print(\"Testing class array size: \" + str(test_class.shape))\n",
    "print(\"Testing data array size: \" + str(test_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c45c9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the final model \n",
    "saved_w = 'distance'\n",
    "#saved_w = 'uniform'\n",
    "saved_k = 7\n",
    "#saved_k = 9\n",
    "def k_nearest_neighbor(X):\n",
    "    '''\n",
    "    X: array of input that wants to be classified\n",
    "    X can have length 1 or more\n",
    "    '''\n",
    "    knn = KNeighborsClassifier(n_neighbors= saved_k, weights = saved_w)\n",
    "    knn.fit(train_data, train_class.ravel())\n",
    "    return knn.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a9b38b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.95      0.98        21\n",
      "         1.0       0.95      1.00      0.97        19\n",
      "\n",
      "    accuracy                           0.97        40\n",
      "   macro avg       0.97      0.98      0.97        40\n",
      "weighted avg       0.98      0.97      0.98        40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Testing with our own testing files\n",
    "test_pred = k_nearest_neighbor(test_data)\n",
    "print(classification_report(test_pred, test_class))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
